{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a28f50b0",
   "metadata": {},
   "source": [
    "Title: Sentiment Analysis on a Custom Text Dataset    \n",
    "Author: Raikibul Hasan"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "081ab703",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Preparation](#toc1_)    \n",
    "    - [Install libraries](#toc1_1_1_)    \n",
    "    - [Import libraries](#toc1_1_2_)    \n",
    "- [Data Expolaration](#toc2_)  \n",
    "    - [Load the dataset & overview of the data](#_)     \n",
    "    - [Identify and handling missing data](#_)      \n",
    "    - [Visualize the distribution](#_)   \n",
    "- [Sentiment Analysis](#toc3_)\n",
    "    <!-- - [Overview of the data](#)   \n",
    "    - [Extract keyword using PKE](#toc2_1_1_)    \n",
    "    - [Split the article into an array/list of individual sentences](#toc2_1_2_)    \n",
    "    - [Map the sentences which contain the keywords](#toc2_1_3_)    \n",
    "    - [Get the sense of the word](#toc2_1_4_)    \n",
    "    - [first distractor generate from WordNet](#toc2_1_5_)    \n",
    "    - [Second distractor generator](#toc2_1_6_)    \n",
    "    - [Find and map the distractors to the keywords](#toc2_1_7_)     -->\n",
    "    <!--/- [Show generates MCQ](#toc2_1_8_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c26e316",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Preparation](#toc0_)\n",
    "In this section, we will import the necessary libraries and dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4f324dc",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_1_'></a>[Install libraries](#toc0_)\n",
    "***If you have installed  library once skip it otherwise make installed varibale false and run***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8ede380",
   "metadata": {},
   "outputs": [],
   "source": [
    "installed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "28f37794",
   "metadata": {},
   "outputs": [],
   "source": [
    "def install_library():\n",
    "    !pip install pandas\n",
    "    !pip install numpy\n",
    "    !pip install worldcloud\n",
    "    !pip install nltk\n",
    "    !pip install seaborn\n",
    "    !pip install tensorflow\n",
    "    !pip install matplotlib\n",
    "    !pip install scikit-learn\n",
    "    !pip install xgboost\n",
    "\n",
    "\n",
    "if not installed:\n",
    "    install_library()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cee42fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\sentLens-env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout, Bidirectional, Concatenate, Flatten\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "607a1a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9f99c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'dataset.csv'\n",
    "data = pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "021daf64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>username</th>\n",
       "      <th>like_count</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-29 22:58:21+00:00</td>\n",
       "      <td>1641213230730051584</td>\n",
       "      <td>Free AI marketing and automation tools, strate...</td>\n",
       "      <td>RealProfitPros</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-29 22:58:18+00:00</td>\n",
       "      <td>1641213218520481805</td>\n",
       "      <td>@MecoleHardman4 Chat GPT says it’s 15. 😂</td>\n",
       "      <td>AmyLouWho321</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-29 22:57:53+00:00</td>\n",
       "      <td>1641213115684536323</td>\n",
       "      <td>https://t.co/FjJSprt0te - Chat with any PDF!\\n...</td>\n",
       "      <td>yjleon1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-29 22:57:52+00:00</td>\n",
       "      <td>1641213110915571715</td>\n",
       "      <td>AI muses: \"In the court of life, we must all f...</td>\n",
       "      <td>ChatGPT_Thinks</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-29 22:57:26+00:00</td>\n",
       "      <td>1641213003260633088</td>\n",
       "      <td>Most people haven't heard of Chat GPT yet.\\nFi...</td>\n",
       "      <td>nikocosmonaut</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-03-29 22:57:20+00:00</td>\n",
       "      <td>1641212975012016128</td>\n",
       "      <td>@nytimes No! Chat Gpt has been putting togethe...</td>\n",
       "      <td>cordydbarb</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-03-29 22:57:06+00:00</td>\n",
       "      <td>1641212917868646400</td>\n",
       "      <td>@ylzkrtt Yes also by chat gpt you can make gen...</td>\n",
       "      <td>gomezfidelphani</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-03-29 22:57:02+00:00</td>\n",
       "      <td>1641212902375063552</td>\n",
       "      <td>@robinhanson @razibkhan Most people haven't he...</td>\n",
       "      <td>nikocosmonaut</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-03-29 22:56:52+00:00</td>\n",
       "      <td>1641212856984109072</td>\n",
       "      <td>Yours Robotically - by Shaun Usher - Letters o...</td>\n",
       "      <td>lawyermarketer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-03-29 22:56:49+00:00</td>\n",
       "      <td>1641212845441585152</td>\n",
       "      <td>This is a metaphor for the limited perception ...</td>\n",
       "      <td>ashleighgrente2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-03-29 22:56:48+00:00</td>\n",
       "      <td>1641212842828533761</td>\n",
       "      <td>Anyone familiar with The \"cave allegory\"? In t...</td>\n",
       "      <td>ashleighgrente2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-03-29 22:56:30+00:00</td>\n",
       "      <td>1641212765355352064</td>\n",
       "      <td>@ThatOuternaut HEY CHAT GPT I DON'T GOT TIME F...</td>\n",
       "      <td>puppetsucks</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-03-29 22:55:26+00:00</td>\n",
       "      <td>1641212499537305600</td>\n",
       "      <td>#GenerativeAI  such as #ChatGPT could replace ...</td>\n",
       "      <td>StevenS23337721</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023-03-29 22:55:22+00:00</td>\n",
       "      <td>1641212479517671427</td>\n",
       "      <td>@rasbt Reading it right now love the fact that...</td>\n",
       "      <td>doomer_says</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2023-03-29 22:55:03+00:00</td>\n",
       "      <td>1641212400367181825</td>\n",
       "      <td>The oracle is a program created by the machine...</td>\n",
       "      <td>ethanbeard91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2023-03-29 22:54:46+00:00</td>\n",
       "      <td>1641212328900284418</td>\n",
       "      <td>You know what a good feature be in ChatGPT @Op...</td>\n",
       "      <td>a_hafez12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2023-03-29 22:54:16+00:00</td>\n",
       "      <td>1641212202593193984</td>\n",
       "      <td>#BCM325 I asked #ChatGPT how The Matrix (1999)...</td>\n",
       "      <td>andreamrra</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2023-03-29 22:54:14+00:00</td>\n",
       "      <td>1641212198180511745</td>\n",
       "      <td>Though it primarily targets companies like Tik...</td>\n",
       "      <td>crypto_talkies</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2023-03-29 22:53:58+00:00</td>\n",
       "      <td>1641212130757337088</td>\n",
       "      <td>By harnessing the power of technology, we can ...</td>\n",
       "      <td>Astrificabo</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2023-03-29 22:53:47+00:00</td>\n",
       "      <td>1641212081780260864</td>\n",
       "      <td>The future is in the integrations. It won't be...</td>\n",
       "      <td>StillHerein2023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2023-03-29 22:53:43+00:00</td>\n",
       "      <td>1641212064705449985</td>\n",
       "      <td>@techAU @elonmusk @TheChiefNerd Walt Disney tr...</td>\n",
       "      <td>SpiderMonkeyXYZ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2023-03-29 22:53:17+00:00</td>\n",
       "      <td>1641211957201055748</td>\n",
       "      <td>@sama Not able to signup in chat GPT. Tried ma...</td>\n",
       "      <td>kksunil53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2023-03-29 22:53:08+00:00</td>\n",
       "      <td>1641211919532015622</td>\n",
       "      <td>Teaching self-management skills?\\nCheck out ou...</td>\n",
       "      <td>ShiftingSchools</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2023-03-29 22:53:01+00:00</td>\n",
       "      <td>1641211891484708865</td>\n",
       "      <td>Can anyone name what's wrong with this pic? \\n...</td>\n",
       "      <td>HottiesBite</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2023-03-29 22:53:00+00:00</td>\n",
       "      <td>1641211884736061440</td>\n",
       "      <td>Looking for new ways to improve your tweets? \\...</td>\n",
       "      <td>0xPromptcraft</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2023-03-29 22:52:32+00:00</td>\n",
       "      <td>1641211766725312512</td>\n",
       "      <td>Is ChatGPT moving too fast? \\n#chatgpt #chatgp...</td>\n",
       "      <td>Dr_liz_X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2023-03-29 22:52:12+00:00</td>\n",
       "      <td>1641211682516004864</td>\n",
       "      <td>I made a cool app using ChatGPT today. \\n\\nMy ...</td>\n",
       "      <td>jak_vault</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2023-03-29 22:52:08+00:00</td>\n",
       "      <td>1641211666762178561</td>\n",
       "      <td>ChatGPT: Why we're still smarter than machines...</td>\n",
       "      <td>roxana_huaman</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2023-03-29 22:52:05+00:00</td>\n",
       "      <td>1641211654703845376</td>\n",
       "      <td>ChatGPT 4 playing Zork. Unclear if it is scrap...</td>\n",
       "      <td>stuartcarnie</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2023-03-29 22:51:56+00:00</td>\n",
       "      <td>1641211619018526721</td>\n",
       "      <td>Run a Gpt 4 chat-based chatbot in your laptop\\...</td>\n",
       "      <td>BadrBellaj</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2023-03-29 22:51:41+00:00</td>\n",
       "      <td>1641211554476576770</td>\n",
       "      <td>@elonmusk @TheChiefNerd Policymakers are the w...</td>\n",
       "      <td>iamhilarry3090</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2023-03-29 22:51:26+00:00</td>\n",
       "      <td>1641211491905941505</td>\n",
       "      <td>&amp;lt;script&amp;gt;alert('XSS')&amp;lt;/script&amp;gt; by #...</td>\n",
       "      <td>CB4KKER</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2023-03-29 22:50:57+00:00</td>\n",
       "      <td>1641211369717485569</td>\n",
       "      <td>@lolia210 Im assuming that one is for copy? I ...</td>\n",
       "      <td>Bimbochan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2023-03-29 22:50:30+00:00</td>\n",
       "      <td>1641211257318457344</td>\n",
       "      <td>So ChatGPT and I did a lot of work tonight. We...</td>\n",
       "      <td>OndrejTucny</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2023-03-29 22:50:29+00:00</td>\n",
       "      <td>1641211252100956162</td>\n",
       "      <td>@DavidSacks Very cool! \\n\\nI liked the article...</td>\n",
       "      <td>Resonator_Steve</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2023-03-29 22:50:11+00:00</td>\n",
       "      <td>1641211175185596419</td>\n",
       "      <td>It's taken me 40+ years to conclude that job d...</td>\n",
       "      <td>LouA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2023-03-29 22:49:58+00:00</td>\n",
       "      <td>1641211124296335360</td>\n",
       "      <td>To be fair, real human lawyers draft illegal s...</td>\n",
       "      <td>AttorneyAtEase</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2023-03-29 22:49:56+00:00</td>\n",
       "      <td>1641211113114152961</td>\n",
       "      <td>totally fascinating, no unexpected\\nthere is a...</td>\n",
       "      <td>chrisdavisLens</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2023-03-29 22:49:41+00:00</td>\n",
       "      <td>1641211051076362240</td>\n",
       "      <td>Lots of teachers worrying about Chat GPT makin...</td>\n",
       "      <td>giordano_lives</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2023-03-29 22:49:27+00:00</td>\n",
       "      <td>1641210993773608960</td>\n",
       "      <td>Just finished having #ChatGPT  write a roughly...</td>\n",
       "      <td>HoosierHardware</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2023-03-29 22:48:59+00:00</td>\n",
       "      <td>1641210876681244672</td>\n",
       "      <td>I had ChatGPT write the worst Tinder pickup li...</td>\n",
       "      <td>TheSatireShow</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2023-03-29 22:48:52+00:00</td>\n",
       "      <td>1641210847581155329</td>\n",
       "      <td>@fada_azeda chat gpt</td>\n",
       "      <td>chemistrul</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2023-03-29 22:48:37+00:00</td>\n",
       "      <td>1641210784171675649</td>\n",
       "      <td>@scottfgray You're not wrong, but for what it'...</td>\n",
       "      <td>groudon466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2023-03-29 22:48:28+00:00</td>\n",
       "      <td>1641210743369396225</td>\n",
       "      <td>@nertilqatja @michael_dehart @greg16676935420 ...</td>\n",
       "      <td>Wil_Le_Debile</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2023-03-29 22:48:16+00:00</td>\n",
       "      <td>1641210694614892544</td>\n",
       "      <td>Just experimented to see if #ChatGPT could hel...</td>\n",
       "      <td>BrianNegus</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2023-03-29 22:48:14+00:00</td>\n",
       "      <td>1641210684854657024</td>\n",
       "      <td>If you’ve been using chat gpt efficiently for ...</td>\n",
       "      <td>riizzlerr</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2023-03-29 22:47:50+00:00</td>\n",
       "      <td>1641210585147932675</td>\n",
       "      <td>GM!☕️☀️ \\nJust aped 3 eth in #GPT4 and it is p...</td>\n",
       "      <td>ramazanismail1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2023-03-29 22:47:10+00:00</td>\n",
       "      <td>1641210416025210880</td>\n",
       "      <td>#chatgpt describing cyberpunk in the matrix as...</td>\n",
       "      <td>byronsmith2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2023-03-29 22:46:59+00:00</td>\n",
       "      <td>1641210371037097984</td>\n",
       "      <td>I asked Chat GPT about defensive football. \\n\\...</td>\n",
       "      <td>janufooty</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2023-03-29 22:46:37+00:00</td>\n",
       "      <td>1641210280209252352</td>\n",
       "      <td>@enamara I've tried them both. I think it is d...</td>\n",
       "      <td>DennisAguma</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         date                   id  \\\n",
       "0   2023-03-29 22:58:21+00:00  1641213230730051584   \n",
       "1   2023-03-29 22:58:18+00:00  1641213218520481805   \n",
       "2   2023-03-29 22:57:53+00:00  1641213115684536323   \n",
       "3   2023-03-29 22:57:52+00:00  1641213110915571715   \n",
       "4   2023-03-29 22:57:26+00:00  1641213003260633088   \n",
       "5   2023-03-29 22:57:20+00:00  1641212975012016128   \n",
       "6   2023-03-29 22:57:06+00:00  1641212917868646400   \n",
       "7   2023-03-29 22:57:02+00:00  1641212902375063552   \n",
       "8   2023-03-29 22:56:52+00:00  1641212856984109072   \n",
       "9   2023-03-29 22:56:49+00:00  1641212845441585152   \n",
       "10  2023-03-29 22:56:48+00:00  1641212842828533761   \n",
       "11  2023-03-29 22:56:30+00:00  1641212765355352064   \n",
       "12  2023-03-29 22:55:26+00:00  1641212499537305600   \n",
       "13  2023-03-29 22:55:22+00:00  1641212479517671427   \n",
       "14  2023-03-29 22:55:03+00:00  1641212400367181825   \n",
       "15  2023-03-29 22:54:46+00:00  1641212328900284418   \n",
       "16  2023-03-29 22:54:16+00:00  1641212202593193984   \n",
       "17  2023-03-29 22:54:14+00:00  1641212198180511745   \n",
       "18  2023-03-29 22:53:58+00:00  1641212130757337088   \n",
       "19  2023-03-29 22:53:47+00:00  1641212081780260864   \n",
       "20  2023-03-29 22:53:43+00:00  1641212064705449985   \n",
       "21  2023-03-29 22:53:17+00:00  1641211957201055748   \n",
       "22  2023-03-29 22:53:08+00:00  1641211919532015622   \n",
       "23  2023-03-29 22:53:01+00:00  1641211891484708865   \n",
       "24  2023-03-29 22:53:00+00:00  1641211884736061440   \n",
       "25  2023-03-29 22:52:32+00:00  1641211766725312512   \n",
       "26  2023-03-29 22:52:12+00:00  1641211682516004864   \n",
       "27  2023-03-29 22:52:08+00:00  1641211666762178561   \n",
       "28  2023-03-29 22:52:05+00:00  1641211654703845376   \n",
       "29  2023-03-29 22:51:56+00:00  1641211619018526721   \n",
       "30  2023-03-29 22:51:41+00:00  1641211554476576770   \n",
       "31  2023-03-29 22:51:26+00:00  1641211491905941505   \n",
       "32  2023-03-29 22:50:57+00:00  1641211369717485569   \n",
       "33  2023-03-29 22:50:30+00:00  1641211257318457344   \n",
       "34  2023-03-29 22:50:29+00:00  1641211252100956162   \n",
       "35  2023-03-29 22:50:11+00:00  1641211175185596419   \n",
       "36  2023-03-29 22:49:58+00:00  1641211124296335360   \n",
       "37  2023-03-29 22:49:56+00:00  1641211113114152961   \n",
       "38  2023-03-29 22:49:41+00:00  1641211051076362240   \n",
       "39  2023-03-29 22:49:27+00:00  1641210993773608960   \n",
       "40  2023-03-29 22:48:59+00:00  1641210876681244672   \n",
       "41  2023-03-29 22:48:52+00:00  1641210847581155329   \n",
       "42  2023-03-29 22:48:37+00:00  1641210784171675649   \n",
       "43  2023-03-29 22:48:28+00:00  1641210743369396225   \n",
       "44  2023-03-29 22:48:16+00:00  1641210694614892544   \n",
       "45  2023-03-29 22:48:14+00:00  1641210684854657024   \n",
       "46  2023-03-29 22:47:50+00:00  1641210585147932675   \n",
       "47  2023-03-29 22:47:10+00:00  1641210416025210880   \n",
       "48  2023-03-29 22:46:59+00:00  1641210371037097984   \n",
       "49  2023-03-29 22:46:37+00:00  1641210280209252352   \n",
       "\n",
       "                                              content         username  \\\n",
       "0   Free AI marketing and automation tools, strate...   RealProfitPros   \n",
       "1            @MecoleHardman4 Chat GPT says it’s 15. 😂     AmyLouWho321   \n",
       "2   https://t.co/FjJSprt0te - Chat with any PDF!\\n...       yjleon1976   \n",
       "3   AI muses: \"In the court of life, we must all f...   ChatGPT_Thinks   \n",
       "4   Most people haven't heard of Chat GPT yet.\\nFi...    nikocosmonaut   \n",
       "5   @nytimes No! Chat Gpt has been putting togethe...       cordydbarb   \n",
       "6   @ylzkrtt Yes also by chat gpt you can make gen...  gomezfidelphani   \n",
       "7   @robinhanson @razibkhan Most people haven't he...    nikocosmonaut   \n",
       "8   Yours Robotically - by Shaun Usher - Letters o...   lawyermarketer   \n",
       "9   This is a metaphor for the limited perception ...  ashleighgrente2   \n",
       "10  Anyone familiar with The \"cave allegory\"? In t...  ashleighgrente2   \n",
       "11  @ThatOuternaut HEY CHAT GPT I DON'T GOT TIME F...      puppetsucks   \n",
       "12  #GenerativeAI  such as #ChatGPT could replace ...  StevenS23337721   \n",
       "13  @rasbt Reading it right now love the fact that...      doomer_says   \n",
       "14  The oracle is a program created by the machine...     ethanbeard91   \n",
       "15  You know what a good feature be in ChatGPT @Op...        a_hafez12   \n",
       "16  #BCM325 I asked #ChatGPT how The Matrix (1999)...       andreamrra   \n",
       "17  Though it primarily targets companies like Tik...   crypto_talkies   \n",
       "18  By harnessing the power of technology, we can ...      Astrificabo   \n",
       "19  The future is in the integrations. It won't be...  StillHerein2023   \n",
       "20  @techAU @elonmusk @TheChiefNerd Walt Disney tr...  SpiderMonkeyXYZ   \n",
       "21  @sama Not able to signup in chat GPT. Tried ma...        kksunil53   \n",
       "22  Teaching self-management skills?\\nCheck out ou...  ShiftingSchools   \n",
       "23  Can anyone name what's wrong with this pic? \\n...      HottiesBite   \n",
       "24  Looking for new ways to improve your tweets? \\...    0xPromptcraft   \n",
       "25  Is ChatGPT moving too fast? \\n#chatgpt #chatgp...         Dr_liz_X   \n",
       "26  I made a cool app using ChatGPT today. \\n\\nMy ...        jak_vault   \n",
       "27  ChatGPT: Why we're still smarter than machines...    roxana_huaman   \n",
       "28  ChatGPT 4 playing Zork. Unclear if it is scrap...     stuartcarnie   \n",
       "29  Run a Gpt 4 chat-based chatbot in your laptop\\...       BadrBellaj   \n",
       "30  @elonmusk @TheChiefNerd Policymakers are the w...   iamhilarry3090   \n",
       "31  &lt;script&gt;alert('XSS')&lt;/script&gt; by #...          CB4KKER   \n",
       "32  @lolia210 Im assuming that one is for copy? I ...        Bimbochan   \n",
       "33  So ChatGPT and I did a lot of work tonight. We...      OndrejTucny   \n",
       "34  @DavidSacks Very cool! \\n\\nI liked the article...  Resonator_Steve   \n",
       "35  It's taken me 40+ years to conclude that job d...             LouA   \n",
       "36  To be fair, real human lawyers draft illegal s...   AttorneyAtEase   \n",
       "37  totally fascinating, no unexpected\\nthere is a...   chrisdavisLens   \n",
       "38  Lots of teachers worrying about Chat GPT makin...   giordano_lives   \n",
       "39  Just finished having #ChatGPT  write a roughly...  HoosierHardware   \n",
       "40  I had ChatGPT write the worst Tinder pickup li...    TheSatireShow   \n",
       "41                               @fada_azeda chat gpt       chemistrul   \n",
       "42  @scottfgray You're not wrong, but for what it'...       groudon466   \n",
       "43  @nertilqatja @michael_dehart @greg16676935420 ...    Wil_Le_Debile   \n",
       "44  Just experimented to see if #ChatGPT could hel...       BrianNegus   \n",
       "45  If you’ve been using chat gpt efficiently for ...        riizzlerr   \n",
       "46  GM!☕️☀️ \\nJust aped 3 eth in #GPT4 and it is p...   ramazanismail1   \n",
       "47  #chatgpt describing cyberpunk in the matrix as...   byronsmith2000   \n",
       "48  I asked Chat GPT about defensive football. \\n\\...        janufooty   \n",
       "49  @enamara I've tried them both. I think it is d...      DennisAguma   \n",
       "\n",
       "    like_count  retweet_count  \n",
       "0          0.0            0.0  \n",
       "1          0.0            0.0  \n",
       "2          0.0            0.0  \n",
       "3          0.0            0.0  \n",
       "4          0.0            0.0  \n",
       "5          0.0            0.0  \n",
       "6          1.0            0.0  \n",
       "7          0.0            0.0  \n",
       "8          0.0            0.0  \n",
       "9          2.0            0.0  \n",
       "10         0.0            0.0  \n",
       "11         2.0            0.0  \n",
       "12         0.0            0.0  \n",
       "13         0.0            0.0  \n",
       "14         0.0            0.0  \n",
       "15         1.0            0.0  \n",
       "16         0.0            0.0  \n",
       "17         0.0            0.0  \n",
       "18         0.0            0.0  \n",
       "19         0.0            0.0  \n",
       "20         0.0            0.0  \n",
       "21         0.0            0.0  \n",
       "22         0.0            0.0  \n",
       "23         1.0            1.0  \n",
       "24         0.0            0.0  \n",
       "25         0.0            0.0  \n",
       "26         0.0            0.0  \n",
       "27         0.0            0.0  \n",
       "28         0.0            0.0  \n",
       "29         0.0            0.0  \n",
       "30         1.0            0.0  \n",
       "31         0.0            0.0  \n",
       "32         0.0            0.0  \n",
       "33         1.0            0.0  \n",
       "34         1.0            0.0  \n",
       "35         1.0            0.0  \n",
       "36         0.0            1.0  \n",
       "37         0.0            0.0  \n",
       "38         1.0            0.0  \n",
       "39         0.0            0.0  \n",
       "40         2.0            0.0  \n",
       "41         0.0            0.0  \n",
       "42         0.0            0.0  \n",
       "43         0.0            0.0  \n",
       "44         0.0            0.0  \n",
       "45         0.0            0.0  \n",
       "46         1.0            0.0  \n",
       "47         0.0            0.0  \n",
       "48         8.0            0.0  \n",
       "49         0.0            0.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "340941e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date              0\n",
       "id                6\n",
       "content           6\n",
       "username         34\n",
       "like_count       62\n",
       "retweet_count    62\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "edbad143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Percentage Missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>date</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>id</td>\n",
       "      <td>0.001200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>content</th>\n",
       "      <td>content</td>\n",
       "      <td>0.001200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>username</th>\n",
       "      <td>username</td>\n",
       "      <td>0.006800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like_count</th>\n",
       "      <td>like_count</td>\n",
       "      <td>0.012399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Column  Percentage Missing\n",
       "date              date            0.000000\n",
       "id                  id            0.001200\n",
       "content        content            0.001200\n",
       "username      username            0.006800\n",
       "like_count  like_count            0.012399"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the percentage of missing values for each column\n",
    "missing_values = data.isnull().sum() / len(data) * 100\n",
    "missing_values_table = pd.DataFrame({'Column': data.columns, 'Percentage Missing': missing_values})\n",
    "missing_values_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop missing values\n",
    "data=data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de7fcfa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date             0\n",
       "id               0\n",
       "content          0\n",
       "username         0\n",
       "like_count       0\n",
       "retweet_count    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38d7af1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7ae5cbc",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['date', 'id', 'username', 'retweet_count'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39;49mdrop(columns\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mdate\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mid\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39musername\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mretweet_count\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m      2\u001b[0m data\u001b[39m.\u001b[39mhead(\u001b[39m2\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sentLens-env\\lib\\site-packages\\pandas\\core\\frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5433\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(\n\u001b[0;32m   5434\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   5435\u001b[0m     labels: IndexLabel \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   5443\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   5444\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   5445\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5446\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5579\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5580\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5581\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[0;32m   5582\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   5583\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   5584\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[0;32m   5585\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   5586\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m   5587\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[0;32m   5588\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   5589\u001b[0m     )\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sentLens-env\\lib\\site-packages\\pandas\\core\\generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4786\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[0;32m   4787\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 4788\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4790\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[0;32m   4791\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sentLens-env\\lib\\site-packages\\pandas\\core\\generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4828\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m   4829\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 4830\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4831\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4833\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4834\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sentLens-env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   7068\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[0;32m   7069\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> 7070\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlabels[mask]\u001b[39m.\u001b[39mtolist()\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   7071\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[0;32m   7072\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['date', 'id', 'username', 'retweet_count'] not found in axis\""
     ]
    }
   ],
   "source": [
    "data = data.drop(columns=['date','id','username','retweet_count'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee1c486d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>like_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Free AI marketing and automation tools, strate...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@MecoleHardman4 Chat GPT says it’s 15. 😂</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  like_count\n",
       "0  Free AI marketing and automation tools, strate...         0.0\n",
       "1           @MecoleHardman4 Chat GPT says it’s 15. 😂         0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentLens-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "149ca6cd89baea70421cc03d8f577b862d0cd31921e4658c13517c9217c8b908"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
